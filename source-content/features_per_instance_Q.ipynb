{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import instance_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./../../Data/parc_features/parc_train_features.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "token_df = pd.read_csv(filepath, delimiter='\\t', index_col=0)\n",
    "token_df = token_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_output = instance_generation.collect_instances_main(token_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_instance_gold(instance_output):\n",
    "    \n",
    "    gold_label_list = list()\n",
    "    pair_list = list()\n",
    "    for instance_list in instance_output:\n",
    "        gold_label_list.append(instance_list[2])\n",
    "        pair_tuple = (instance_list[0], instance_list[1])\n",
    "        pair_list.append(pair_tuple)\n",
    "    \n",
    "    return pair_list, gold_label_list\n",
    "\n",
    "def create_instance_list(list_of_tuples,df):\n",
    "    main_attribution = list()\n",
    "    main_gap = list()\n",
    "\n",
    "    # Loop through instances meaning content and source span indices\n",
    "    for instance in pair_list:\n",
    "        # initiate instance_list and index_list\n",
    "        attribution_indices = list()\n",
    "\n",
    "        source, content = instance\n",
    "        b_source, e_source = source\n",
    "        b_content, e_content = content\n",
    "\n",
    "        # For index of source\n",
    "        for index in range(b_source, e_source+1):  \n",
    "            attribution_indices.append(index)\n",
    "        # for index of content\n",
    "        for index in range(b_content, e_content+1):\n",
    "            attribution_indices.append(index)\n",
    "            \n",
    "        # Find gap indices\n",
    "        if b_source < b_content: \n",
    "            # If content follows source, gap is between last token of source and first of content\n",
    "            gap_indices = [e_source, b_content]\n",
    "        else:\n",
    "            # If source follows content, then visa versa\n",
    "            gap_indices = [e_content, b_source]\n",
    "\n",
    "        main_attribution.append(attribution_indices)\n",
    "        main_gap.append(gap_indices)\n",
    "        \n",
    "    return main_attribution, main_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant lists\n",
    "pair_list, gold_labels = seperate_instance_gold(instance_output)\n",
    "\n",
    "sequence_indices, gap_indices = create_instance_list(pair_list, token_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df = pd.DataFrame()\n",
    "pair_df['source_content_boundaries'] = pair_list\n",
    "pair_df['gold_labels'] = gold_labels\n",
    "pair_df['all_indices_in_span'] = sequence_indices\n",
    "pair_df['gap_indices'] = gap_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_content_boundaries</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>all_indices_in_span</th>\n",
       "      <th>gap_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((58, 59), (57, 89))</td>\n",
       "      <td>0</td>\n",
       "      <td>[58, 59, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...</td>\n",
       "      <td>[89, 58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((60, 61), (57, 89))</td>\n",
       "      <td>0</td>\n",
       "      <td>[60, 61, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...</td>\n",
       "      <td>[89, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((65, 68), (57, 89))</td>\n",
       "      <td>0</td>\n",
       "      <td>[65, 66, 67, 68, 57, 58, 59, 60, 61, 62, 63, 6...</td>\n",
       "      <td>[89, 65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((72, 73), (57, 89))</td>\n",
       "      <td>0</td>\n",
       "      <td>[72, 73, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...</td>\n",
       "      <td>[89, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((74, 76), (57, 89))</td>\n",
       "      <td>0</td>\n",
       "      <td>[74, 75, 76, 57, 58, 59, 60, 61, 62, 63, 64, 6...</td>\n",
       "      <td>[89, 74]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_content_boundaries  gold_labels  \\\n",
       "0      ((58, 59), (57, 89))            0   \n",
       "1      ((60, 61), (57, 89))            0   \n",
       "2      ((65, 68), (57, 89))            0   \n",
       "3      ((72, 73), (57, 89))            0   \n",
       "4      ((74, 76), (57, 89))            0   \n",
       "\n",
       "                                 all_indices_in_span gap_indices  \n",
       "0  [58, 59, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...    [89, 58]  \n",
       "1  [60, 61, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...    [89, 60]  \n",
       "2  [65, 66, 67, 68, 57, 58, 59, 60, 61, 62, 63, 6...    [89, 65]  \n",
       "3  [72, 73, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...    [89, 72]  \n",
       "4  [74, 75, 76, 57, 58, 59, 60, 61, 62, 63, 64, 6...    [89, 74]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_length(df, list_of_tuples): \n",
    "    \"\"\"\n",
    "    Get word length for the content or source in the tuple (specified by s or c)\n",
    "    \"\"\"\n",
    "    \n",
    "    content_len_list = []\n",
    "    source_len_list = []\n",
    "    \n",
    "    for s_tuple, c_tuple in list_of_tuples:\n",
    "        # Get content len\n",
    "        start, end = c_tuple\n",
    "        content_len_list.append(end+1-start)\n",
    "            \n",
    "        # Get source len\n",
    "        start, end = s_tuple\n",
    "        source_len_list.append(end+1-start)\n",
    "    pair_df['content_length'] = content_len_list    \n",
    "    pair_df['source_length'] = source_len_list\n",
    "    \n",
    "def check_s_in_c(token_df, pair_df, list_of_tuples):\n",
    "    results = []\n",
    "    for source_indices, content_indices in list_of_tuples:\n",
    "        b_content, e_content = content_indices\n",
    "        b_source, e_source = source_indices\n",
    "        \n",
    "        s_span = list(token_df.iloc[b_source:e_source+1][\"lemma\"])\n",
    "        c_span = list(token_df.iloc[b_content:e_content+1][\"lemma\"])\n",
    "        bool_ = all(elem in s_span for elem in c_span)\n",
    "        \n",
    "        if bool_ == False:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = 1\n",
    "        results.append(result)\n",
    "        \n",
    "    pair_df['source_in_content'] = results\n",
    "        \n",
    "def get_distance_c2sentstart(token_df, pair_df, list_of_tuples): \n",
    "    distances_2docstart = []\n",
    "    distances_2sentstart = []\n",
    "    \n",
    "    for source_indices, content_indices in list_of_tuples:\n",
    "        b_content, e_content = content_indices\n",
    "        \n",
    "        # Get the distance from the start of the document to the content span.\n",
    "        doc_filename = token_df.iloc[b_content]['filename']\n",
    "        index_doc_start = token_df[token_df.filename == doc_filename].first_valid_index()\n",
    "        \n",
    "        distance_c2doc = b_content - index_doc_start\n",
    "        distances_2docstart.append(distance_c2doc)\n",
    "        \n",
    "        \n",
    "        # Get the distance from the start of the sentence to the content span.\n",
    "        file_df = token_df.loc[df[\"filename\"] == doc_filename] # Filter by filename to get the correct indices.\n",
    "        \n",
    "        sent_id = token_df.iloc[b_content][\"sentence_number\"]\n",
    "        index_sent_start = file_df[token_df.sentence_number == sent_id].first_valid_index()\n",
    "        \n",
    "        distance_c2sent = b_content - index_sent_start\n",
    "        distances_2sentstart.append(distance_c2sent)\n",
    "            \n",
    "    pair_df['distance_c2docstart'] = distances_2docstart\n",
    "    pair_df['distance_c2sentstart'] = distances_2sentstart\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-db2c63aefa48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_word_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source_content_boundaries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_distance_c2sentstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source_content_boundaries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcheck_s_in_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpair_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source_content_boundaries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-7afc895d4060>\u001b[0m in \u001b[0;36mget_distance_c2sentstart\u001b[1;34m(token_df, pair_df, list_of_tuples)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Get the distance from the start of the sentence to the content span.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mfile_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"filename\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdoc_filename\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Filter by filename to get the correct indices.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0msent_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_content\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sentence_number\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "get_word_length(pair_df, pair_df['source_content_boundaries'])\n",
    "get_distance_c2sentstart(token_df, pair_df, pair_df['source_content_boundaries'])\n",
    "check_s_in_c(token_df, pair_df, pair_df['source_content_boundaries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-381649e3f056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_pair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_pair' is not defined"
     ]
    }
   ],
   "source": [
    "pair_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
