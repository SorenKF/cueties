{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import instance_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepath = \"./../../Data/parc_features/parc_train_features.tsv\"\n",
    "test_filepath = \"./../../Data/parc_features/parc_dev_features.tsv\"\n",
    "\n",
    "train_fileout = \"./../../Data/parc_train_features.tsv\"\n",
    "test_fileout = \"./../../Data/parc_dev_features.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_instance_gold(instance_output):\n",
    "    \n",
    "    gold_label_list = list()\n",
    "    pair_list = list()\n",
    "    for instance_list in instance_output:\n",
    "        gold_label_list.append(instance_list[2])\n",
    "        pair_tuple = (instance_list[0], instance_list[1])\n",
    "        pair_list.append(pair_tuple)\n",
    "    \n",
    "    return pair_list, gold_label_list\n",
    "\n",
    "\n",
    "def create_instance_list(list_of_tuples,df):\n",
    "    main_attribution = list()\n",
    "    main_gap = list()\n",
    "\n",
    "    # Loop through instances meaning content and source span indices\n",
    "    for instance in pair_list:\n",
    "        # initiate instance_list and index_list\n",
    "        attribution_indices = list()\n",
    "\n",
    "        source, content = instance\n",
    "        b_source, e_source = source\n",
    "        b_content, e_content = content\n",
    "\n",
    "        # For index of source\n",
    "        for index in range(b_source, e_source+1):  \n",
    "            attribution_indices.append(index)\n",
    "        # for index of content\n",
    "        for index in range(b_content, e_content+1):\n",
    "            attribution_indices.append(index)\n",
    "            \n",
    "        # Find gap indices\n",
    "        if b_source < b_content: \n",
    "            # If content follows source, gap is between last token of source and first of content\n",
    "            gap_indices = [e_source, b_content]\n",
    "        else:\n",
    "            # If source follows content, then visa versa\n",
    "            gap_indices = [e_content, b_source]\n",
    "\n",
    "        main_attribution.append(attribution_indices)\n",
    "        main_gap.append(gap_indices)\n",
    "        \n",
    "    return main_attribution, main_gap\n",
    "\n",
    "\n",
    "def create_instance_list(pair_list, df):\n",
    "    main_attribution = list()\n",
    "    main_gap = list()\n",
    "\n",
    "    # Loop through instances meaning content and source span indices\n",
    "    for instance in pair_list:\n",
    "        # initiate instance_list and index_list\n",
    "        attribution_indices = list()\n",
    "        source, content = instance\n",
    "        b_source, e_source = source\n",
    "        b_content, e_content = content\n",
    "\n",
    "        # For index of source\n",
    "        for index in range(b_source, e_source+1):  \n",
    "            attribution_indices.append(index)\n",
    "        # for index of content\n",
    "        for index in range(b_content, e_content+1):\n",
    "            attribution_indices.append(index)\n",
    "            \n",
    "        # Find gap indices\n",
    "        # If source in content fill gap_indices with 0\n",
    "        if b_source in range(b_content, e_content+1) and e_source in range(b_content, e_content+1):\n",
    "            gap_indices = [0, 0]\n",
    "        # If content in source fill gap_indices with 0\n",
    "        elif b_content in range(b_source, e_source+1) and e_content in range(b_source, e_source+1):\n",
    "            gap_indices = [0, 0]\n",
    "            \n",
    "        elif b_source < b_content: \n",
    "            # If content follows source, gap is between last token of source and first of content\n",
    "            gap_indices = [e_source, b_content]\n",
    "        else:\n",
    "            # If source follows content, then visa versa\n",
    "            gap_indices = [e_content, b_source]\n",
    "            \n",
    "        main_attribution.append(attribution_indices)\n",
    "        main_gap.append(gap_indices)\n",
    "        \n",
    "    return main_attribution, main_gap\n",
    "\n",
    "\n",
    "def get_word_length(pair_df, list_of_tuples): \n",
    "    \"\"\"\n",
    "    Get word length for the content or source in the tuple \n",
    "    \"\"\"\n",
    "    \n",
    "    content_len_list = []\n",
    "    source_len_list = []\n",
    "    \n",
    "    for s_tuple, c_tuple in list_of_tuples:\n",
    "        # Get content len\n",
    "        start, end = c_tuple\n",
    "        content_len_list.append(end+1-start)\n",
    "            \n",
    "        # Get source len\n",
    "        start, end = s_tuple\n",
    "        source_len_list.append(end+1-start)\n",
    "    pair_df['content_length'] = content_len_list    \n",
    "    pair_df['source_length'] = source_len_list\n",
    "    \n",
    "def check_s_in_c(token_df, pair_df, list_of_tuples):\n",
    "    results = []\n",
    "    for source_indices, content_indices in list_of_tuples:\n",
    "        b_content, e_content = content_indices\n",
    "        b_source, e_source = source_indices\n",
    "        \n",
    "        s_span = list(token_df.iloc[b_source:e_source+1][\"lemma\"])\n",
    "        c_span = list(token_df.iloc[b_content:e_content+1][\"lemma\"])\n",
    "        bool_ = all(elem in s_span for elem in c_span)\n",
    "        \n",
    "        if bool_ == False:\n",
    "            result = 0\n",
    "        else:\n",
    "            result = 1\n",
    "        results.append(result)\n",
    "        \n",
    "    pair_df['source_in_content'] = results\n",
    "        \n",
    "def get_distance_c2sentstart(token_df, pair_df, list_of_tuples): \n",
    "    distances_2docstart = []\n",
    "    distances_2sentstart = []\n",
    "    \n",
    "    for source_indices, content_indices in list_of_tuples:\n",
    "        b_content, e_content = content_indices\n",
    "        \n",
    "        # Get the distance from the start of the document to the content span.\n",
    "        doc_filename = token_df.iloc[b_content]['filename']\n",
    "        index_doc_start = token_df[token_df.filename == doc_filename].first_valid_index()\n",
    "        \n",
    "        distance_c2doc = b_content - index_doc_start\n",
    "        distances_2docstart.append(distance_c2doc)\n",
    "        \n",
    "        \n",
    "        # Get the distance from the start of the sentence to the content span.\n",
    "        file_df = token_df.loc[token_df[\"filename\"] == doc_filename] # Filter by filename to get the correct indices.\n",
    "        \n",
    "        sent_id = token_df.iloc[b_content][\"sentence_number\"]\n",
    "        index_sent_start = file_df[token_df.sentence_number == sent_id].first_valid_index()\n",
    "        \n",
    "        distance_c2sent = b_content - index_sent_start\n",
    "        distances_2sentstart.append(distance_c2sent)\n",
    "            \n",
    "    pair_df['distance_c2docstart'] = distances_2docstart\n",
    "    pair_df['distance_c2sentstart'] = distances_2sentstart\n",
    "    \n",
    "def find_sc_dist(pair_df):\n",
    "    \n",
    "    pair_df['s/c_distance'] = 'X'\n",
    "    \n",
    "    dist_list = list()\n",
    "    \n",
    "    for b_gap, e_gap in pair_df['gap_indices']:\n",
    "        \n",
    "        if b_gap == e_gap == 0:\n",
    "            distance = 0        \n",
    "        elif b_gap < e_gap:\n",
    "            distance = e_gap - b_gap\n",
    "        else:\n",
    "            distance = b_gap - e_gap\n",
    "\n",
    "        dist_list.append(distance)\n",
    "        \n",
    "    pair_df['s/c_distance'] = dist_list\n",
    "    \n",
    "def find_num_conts_between(token_df, pair_df):\n",
    "    \n",
    "    pair_df['num_conts_between'] = 'X'\n",
    "    count_list = list()\n",
    "    \n",
    "    for b_gap, e_gap in pair_df['gap_indices']:\n",
    "        if b_gap == e_gap == 0:\n",
    "            counter = 0\n",
    "            count_list.append(counter)\n",
    "        else:\n",
    "            counter = 0\n",
    "            for index in range(b_gap, e_gap):\n",
    "                if token_df.loc[index,'content_label_gold'] == 'B':\n",
    "                    counter += 1\n",
    "            count_list.append(counter)\n",
    "\n",
    "    pair_df['num_conts_between'] = count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_data(filepath):\n",
    "    # Read in token level data\n",
    "    token_df = pd.read_csv(filepath, delimiter='\\t', index_col=0)\n",
    "    token_df = token_df[:500]\n",
    "\n",
    "    instance_output = instance_generation.collect_instances_main(token_df)\n",
    "\n",
    "    # Extract relevant lists\n",
    "    # Pair_list is list of tuples of source and content start and end indices\n",
    "    # Gold_labels is list of labels whether source and content are a match\n",
    "    # Sequence_indices is a list of lists of all the indicis which make up a sequence of soure-content\n",
    "    # Gap_indices is a list of start and end indices of the gap between the source and the content \n",
    "    pair_list, gold_labels = seperate_instance_gold(instance_output)\n",
    "    sequence_indices, gap_indices = create_instance_list(pair_list, token_df)\n",
    "    \n",
    "    #return pair_list, gold_labels, sequence_indices, gap_indices\n",
    "    \n",
    "    assert len(pair_list) == len(gold_labels) == len(sequence_indices) == len(gap_indices), f'Lengths \\\n",
    "    do not match. {len(pair_list)}, {len(gold_labels)}, {len(sequence_indices)}, {len(gap_indices)}.'\n",
    "    \n",
    "    # Create DataFrame to contain pairwise data\n",
    "    pair_df = pd.DataFrame()\n",
    "    pair_df['source_content_boundaries'] = pair_list\n",
    "    pair_df['gold_labels'] = gold_labels\n",
    "    pair_df['all_indices_in_span'] = sequence_indices\n",
    "    pair_df['gap_indices'] = gap_indices\n",
    "\n",
    "    # Add features to dataframe\n",
    "    get_word_length(pair_df, pair_df['source_content_boundaries'])\n",
    "    get_distance_c2sentstart(token_df, pair_df, pair_df['source_content_boundaries'])\n",
    "    check_s_in_c(token_df, pair_df, pair_df['source_content_boundaries'])\n",
    "    find_sc_dist(pair_df)\n",
    "    find_num_conts_between(token_df, pair_df)\n",
    "    \n",
    "    return pair_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:143: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "C:\\Users\\quiri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3248: DtypeWarning: Columns (71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df_train = get_pairwise_data(train_filepath)\n",
    "df_test = get_pairwise_data(test_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(train_fileout, sep='\\t')\n",
    "df_test.to_csv(test_fileout, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
